캐글 - 타이타닉 생존자 예측하기
==============================
(1) 문제 정의하기
-----------------

Titanic - Machine Learning from Disaster 은 Getting Started Prediction Competition으로, 
ML 대회에 처음 도전하고 캐글 플랫폼이 어떻게 작동하는 지 이해하는 데 아주 좋은 대회다.

머신러닝을 이용하여, 어떤 승객이 타이타닉 난파선에서 살아남았는 지 예측하는 모델을 만드는 것이 이 대회의 목적이다.

## Workflow goals
1. Classifying: 샘플을 분류한다. 
2. Correlating: 훈련 데이터셋에 있는 feature와 Solution goal간의 상관관계를 파악하거나, feature 간의 상관관계를 파악한다.
3. Converting: 모델링 단계에서 데이터를 준비할 때, 사용하는 알고리즘에 따라 데이터의 자료형을 바꿔줄 수 있다.
4. Completing: 데이터를 준비하는 과정에서, feature에 누락된 값은 없는 지 추정할 수 있다.
5. Correcting: 훈련 데이터셋에 에러나 부정확한 값이 있는 지 분석할 수 있다.
6. Creating: 기존 feature나 여러 개의 feature의 묶음으로 새로운 feature들을 생성할 수 있다.
7. Charting: 데이터의 특성이나 solution goals에 따라, 올바른 시각화 plot과 chart를 선택하는 방법.

## 필요한 모듈
  # data analysis and wrangling
  import pandas as pd
  import numpy as np
  import random as rnd

  # visualization
  import seaborn as sns
  import matplotlib.pyplot as plt
  %matplotlib inline

  # machine learning
  from sklearn.linear_model import LogisticRegression
  from sklearn.svm import SVC, LinearSVC
  from sklearn.ensemble import RandomForestClassifier
  from sklearn.neighbors import KNeighborsClassifier
  from sklearn.naive_bayes import GaussianNB
  from sklearn.linear_model import Perceptron
  from sklearn.linear_model import SGDClassifier
  from sklearn.tree import DecisionTreeClassifier

본격적인 시작에 앞서, 이 대회에 필요한 머신러닝 알고리즘을 살펴보자. 
1. Logistic Regression(로지스틱 회귀)
2. SVM(Support Vector Machine)
3. Random Forest
4. KNN(K-Neareast Neighbors, 최근접 이웃 알고리즘)
5. Naive Bayes(나이브 베이즈) 분류
6. Decision Tree(의사결정트리)
