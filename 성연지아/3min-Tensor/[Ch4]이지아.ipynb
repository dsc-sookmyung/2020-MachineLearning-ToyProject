{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 4 . 기본신경망 구현 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 인공신경망 \n",
    "    : 입력값 X에 가중치와 편향을 더한 뒤 활성화 함수를 거쳐 결괏값 Y를 만들어 내는 것 \n",
    "\n",
    "### 2) 활성화함수 \n",
    "    \n",
    "   + Sigmoid \\\n",
    "    : 0과 1사이의 값 출력 \n",
    "   + ReLU \\\n",
    "    : 0보다 작으면 0, 0보다 크면 입력값 그대로 출력\n",
    "   + tanh \\\n",
    "    : -1 과 1 사이의 값 출력\n",
    "    \n",
    "### 3) 역전파 \n",
    "    : 출력층의 결과의 오차를 신경망을 따라 입력층까지 역으로 전파하여 계산(가중치 갱신)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-1 Classification\n",
    "\n",
    "#### 분류 : 패턴을 파악해 여러 종류로 구분하는 작업 \n",
    "### <털과 날개를 기준으로 포유류와 조류를 구분하는 모델 구현>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 구성 \n",
    "\n",
    "## [털, 날개]\n",
    "x_data = np.array([[0, 0], [1, 0], [1, 1], [0, 0], [0, 0], [0, 1]])\n",
    "\n",
    "## [기타, 포유류, 조류] : 원-핫 인코딩 형태 \n",
    "y_data = np.array([\n",
    "    [1, 0, 0],  # 기타\n",
    "    [0, 1, 0],  # 포유류\n",
    "    [0, 0, 1],  # 조류\n",
    "    [1, 0, 0],\n",
    "    [1, 0, 0],\n",
    "    [0, 0, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <특정 X와 레이블 Y와의 관계를 알아내는 모델>\n",
    ": X, Y에 실측값을 넣어 학습시킨다. \n",
    "\n",
    "\n",
    "\n",
    "#### - 가중치와 편향 변수 설정\n",
    "  * **가중치 변수 W** : [입력층(특징수), 출력층(레이블 수)]로 설정 \n",
    "  * **편향 변수 b** : 레이블 수로 설정 \n",
    "\n",
    "\n",
    "\n",
    "#### - 신경망의 구성\n",
    "  * **Wx + b의 결과를 활성화 함수 ReLU에 적용하면 끝!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 신경망 모델 구성 \n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# 2차원 신경망[입력층, 출력층] = [2, 3] \n",
    "W = tf.Variable(tf.random_uniform([2, 3], -1., 1.))\n",
    "\n",
    "#출력 개수(레이블 수)인 3으로 설정 \n",
    "b = tf.Variable(tf.zeros([3]))\n",
    "\n",
    "#신경망에 가중치 & 편향 적용\n",
    "L = tf.add(tf.matmul(X, W), b)\n",
    "\n",
    "# 활성화 함수: ReLU 함수 적용\n",
    "L = tf.nn.relu(L)\n",
    "\n",
    "# softmax 함수 적용 : 전체합이 1인 확률로 만들어주는 함수\n",
    "model = tf.nn.softmax(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 손실 함수 작성 \n",
    "## 손실함수는 신경망을 최적화하기 위함임 \n",
    "\n",
    "# Y:실측값 model: 신경망에서 나온 예측값 \n",
    "## 예측값과 실제값 사이의 확률 분포의 차이를 비용으로 계산 : cross-entropy 함수 사용 \n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(model), axis=1))\n",
    "\n",
    "#최적화: 경사하강법 \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 1.0790175\n",
      "20 1.0721449\n",
      "30 1.066224\n",
      "40 1.0619946\n",
      "50 1.0594577\n",
      "60 1.0572492\n",
      "70 1.0552572\n",
      "80 1.0532871\n",
      "90 1.0513235\n",
      "100 1.0493869\n"
     ]
    }
   ],
   "source": [
    "# 4. 모델 학습 \n",
    "\n",
    "#세션 초기화 \n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# 학습 100번 진행\n",
    "for step in range(100):\n",
    "    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "    # 10번에 1번씩 손실값 출력 \n",
    "    if (step + 1) % 10 == 0:\n",
    "        print(step + 1, sess.run(cost, feed_dict={X: x_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값: [0 1 1 0 0 2]\n",
      "실제값: [0 1 2 0 0 2]\n",
      "정확도: 83.33\n"
     ]
    }
   ],
   "source": [
    "# 5. 학습 결과 확인 \n",
    "# 요소 중 가장 큰 값의 인덱스 찾아줌 :argmax (함수)\n",
    "prediction = tf.argmax(model, axis=1)\n",
    "target = tf.argmax(Y, axis=1)\n",
    "print('예측값:', sess.run(prediction, feed_dict={X: x_data}))\n",
    "print('실제값:', sess.run(target, feed_dict={Y: y_data}))\n",
    "\n",
    "# 6. 정확도 출력 \n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 횟수를 늘려도 정확도가 높여지지 않는다!\n",
    "<span style=\"color:red\"> 이유: 신경망이 한 층 밖에 안되기 때문에</span> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2 Deep Nerual Network\n",
    "#### 심층 신경망 : 신경망의 레이어를 여러개로 구성 :: 딥러닝 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <위의 신경망 모델에 가중치와 편향 추가하기>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 신경망 모델 구성 (데이터는 위의 데이터 사용)\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# 첫번째 가중치: [2, 10] \n",
    "W1 = tf.Variable(tf.random_uniform([2, 10], -1., 1.))\n",
    "\n",
    "# 두번째 가중치:[10, 3] \n",
    "W2 = tf.Variable(tf.random_uniform([10, 3], -1., 1.))\n",
    "\n",
    "# 편향: 각 레이어의 아웃풋 갯수\n",
    "## b1 : 히든 레이어(은닉층)의 뉴런 갯수인 10 \n",
    "b1 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "## b2 : 최종 결과값 (분류개수)인 3\n",
    "b2 = tf.Variable(tf.zeros([3]))\n",
    "\n",
    "L1 = tf.add(tf.matmul(X, W1), b1)\n",
    "L1 = tf.nn.relu(L1)\n",
    "\n",
    "# 두번째 가중치 W2와 편향 b2를 적용 : 최종 3개의 출력값 \n",
    "model = tf.add(tf.matmul(L1, W2), b2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 손실함수 작성\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=model))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.7081044\n",
      "20 0.55829155\n",
      "30 0.4433968\n",
      "40 0.34239185\n",
      "50 0.25619677\n",
      "60 0.18369663\n",
      "70 0.12782663\n",
      "80 0.0881943\n",
      "90 0.061717447\n",
      "100 0.04436257\n",
      "예측값: [0 1 2 0 0 2]\n",
      "실제값: [0 1 2 0 0 2]\n",
      "정확도: 100.00\n"
     ]
    }
   ],
   "source": [
    "# 3. 모델 학습 \n",
    "\n",
    "#세션 초기화 \n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# 학습 100번 진행\n",
    "for step in range(100):\n",
    "    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "    # 10번에 1번씩 손실값 출력 \n",
    "    if (step + 1) % 10 == 0:\n",
    "        print(step + 1, sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "        \n",
    "# 4. 학습 결과 확인 \n",
    "# 요소 중 가장 큰 값의 인덱스 찾아줌 :argmax (함수)\n",
    "prediction = tf.argmax(model, axis=1)\n",
    "target = tf.argmax(Y, axis=1)\n",
    "print('예측값:', sess.run(prediction, feed_dict={X: x_data}))\n",
    "print('실제값:', sess.run(target, feed_dict={Y: y_data}))\n",
    "\n",
    "# 5. 정확도 출력 \n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_data, Y: y_data}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
